## Text Classifier using BERT for Sentiment Analysis

This project is a text classifier that uses DistilBERT (a distilled version of BERT) to classify text into sentiment categories (positive, negative, neutral)

[**DistilBERT**](https://huggingface.co/distilbert-base-uncased)
- DistilBERT is a smaller and faster version of BERT that has been pre-trained on the same corpus, so it can still learn the contextual relationships between words while being more efficient.

[**Dataset**](https://huggingface.co/datasets/emad12/stock_tweets_sentiment)

- This set of data has about 96,000 examples for training and 24,000 for testing. I've used only the training part for my project. You can find this dataset on [Hugging Face](https://huggingface.co/datasets/emad12/stock_tweets_sentiment)
